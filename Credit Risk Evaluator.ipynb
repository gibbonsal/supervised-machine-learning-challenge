{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction: \n",
    "#I believe that Logistic Regression will perform better than Random Forest. Even though the decision tree\n",
    "#model is made for sectors like loan risk, having the training data in 2019 and the testing \n",
    "#data fir the first quarter in 2020 will strongly test boths model's predictive capacities.\n",
    "#Random Forest does not do as well with numerical features outside the realm of the \n",
    "#training data. 2019 was a relatively stable year financially, and there is a lot more data to \n",
    "#mitigate and variance, so there will be fewer outliers. However, we have fewer samples in for the\n",
    "#first quarter of 2020 (12181 samples for 2019 and 4703), and the last few weeks of the quarter\n",
    "#ends will the lockdown, so I predict there will be quite a few outliers, and that economic \n",
    "#turbulence due to the pandemic will have an impact on the data and will hinder \n",
    "#Random Forest's ability to predict loan risk in 2020.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         low_risk\n",
       "1         low_risk\n",
       "2         low_risk\n",
       "3         low_risk\n",
       "4         low_risk\n",
       "           ...    \n",
       "12175    high_risk\n",
       "12176    high_risk\n",
       "12177    high_risk\n",
       "12178    high_risk\n",
       "12179    high_risk\n",
       "Name: loan_status, Length: 12180, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "\n",
    "X_train_df = train_df.drop(columns=[\"loan_status\"])\n",
    "y_train_df = train_df[\"loan_status\"]\n",
    "\n",
    "X_train_df = pd.get_dummies(X_train_df, dummy_na=True)\n",
    "\n",
    "y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'loan_amnt', 'int_rate', 'installment',\n",
       "       'annual_inc', 'dti', 'delinq_2yrs', 'inq_last_6mths', 'open_acc',\n",
       "       ...\n",
       "       'initial_list_status_nan', 'application_type_Individual',\n",
       "       'application_type_Joint App', 'application_type_nan', 'hardship_flag_N',\n",
       "       'hardship_flag_Y', 'hardship_flag_nan', 'debt_settlement_flag_N',\n",
       "       'debt_settlement_flag_Y', 'debt_settlement_flag_nan'],\n",
       "      dtype='object', length=101)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>...</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <th>initial_list_status_nan</th>\n",
       "      <th>application_type_Individual</th>\n",
       "      <th>application_type_Joint App</th>\n",
       "      <th>application_type_nan</th>\n",
       "      <th>hardship_flag_N</th>\n",
       "      <th>hardship_flag_Y</th>\n",
       "      <th>hardship_flag_nan</th>\n",
       "      <th>debt_settlement_flag_N</th>\n",
       "      <th>debt_settlement_flag_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67991</td>\n",
       "      <td>67991</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>814.70</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>19.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25429</td>\n",
       "      <td>25429</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>208.70</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>11.52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38496</td>\n",
       "      <td>38496</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>128.27</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>6.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19667</td>\n",
       "      <td>19667</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>478.33</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>12.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37505</td>\n",
       "      <td>37505</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>120.27</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>16.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index  loan_amnt  int_rate  installment  annual_inc    dti  \\\n",
       "0       67991  67991    40000.0    0.0819       814.70    140000.0  19.75   \n",
       "1       25429  25429     6000.0    0.1524       208.70     55000.0  11.52   \n",
       "2       38496  38496     3600.0    0.1695       128.27     42000.0   6.74   \n",
       "3       19667  19667    20000.0    0.1524       478.33    100000.0  12.13   \n",
       "4       37505  37505     3600.0    0.1240       120.27     50000.0  16.08   \n",
       "\n",
       "   delinq_2yrs  inq_last_6mths  open_acc  ...  initial_list_status_w  \\\n",
       "0          0.0             1.0      18.0  ...                      1   \n",
       "1          2.0             0.0       8.0  ...                      1   \n",
       "2          0.0             0.0       6.0  ...                      1   \n",
       "3          0.0             2.0       7.0  ...                      1   \n",
       "4          0.0             3.0       6.0  ...                      1   \n",
       "\n",
       "   initial_list_status_nan  application_type_Individual  \\\n",
       "0                        0                            1   \n",
       "1                        0                            1   \n",
       "2                        0                            1   \n",
       "3                        0                            1   \n",
       "4                        0                            1   \n",
       "\n",
       "   application_type_Joint App  application_type_nan  hardship_flag_N  \\\n",
       "0                           0                     0                1   \n",
       "1                           0                     0                1   \n",
       "2                           0                     0                1   \n",
       "3                           0                     0                1   \n",
       "4                           0                     0                1   \n",
       "\n",
       "   hardship_flag_Y  hardship_flag_nan  debt_settlement_flag_N  \\\n",
       "0                0                  0                       1   \n",
       "1                0                  0                       1   \n",
       "2                0                  0                       1   \n",
       "3                0                  0                       1   \n",
       "4                0                  0                       1   \n",
       "\n",
       "   debt_settlement_flag_nan  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric and separate target feature for testing data\n",
    "\n",
    "\n",
    "X_test_df = test_df.drop(columns=[\"loan_status\"])\n",
    "y_test_df = test_df[\"loan_status\"]\n",
    "\n",
    "X_test_df = pd.get_dummies(test_df, dummy_na=True)\n",
    "X_test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 103)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure the test and train columns match.\n",
    "\n",
    "len (X_train_df.columns), len(X_test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_status_high_risk\n",
      "loan_status_low_risk\n",
      "loan_status_nan\n"
     ]
    }
   ],
   "source": [
    "# Add missing dummy variables to testing set\n",
    "\n",
    "for col in X_test_df.columns:\n",
    "    if col not in X_train_df.columns:\n",
    "         print(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debt_settlement_flag_Y\n"
     ]
    }
   ],
   "source": [
    "#Find any columns in the training set that need to be dropped.\n",
    "\n",
    "for col in X_train_df.columns:\n",
    "    if col not in X_test_df.columns:\n",
    "         print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing dummy variables to testing set and drop the extra column\n",
    "\n",
    "X_train_df[\"loan_status_high_risk\"] = 0\n",
    "X_train_df[\"loan_status_low_risk\"] = 0\n",
    "X_train_df[\"loan_status_nan\"] = 0\n",
    "\n",
    "X_train_df = X_train_df.drop(columns=['debt_settlement_flag_Y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 103)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (X_train_df.columns), len(X_test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12180 entries, 0 to 12179\n",
      "Columns: 103 entries, Unnamed: 0 to loan_status_nan\n",
      "dtypes: float64(76), int64(5), uint8(22)\n",
      "memory usage: 7.8 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4702 entries, 0 to 4701\n",
      "Columns: 103 entries, Unnamed: 0 to debt_settlement_flag_nan\n",
      "dtypes: float64(76), int64(2), uint8(25)\n",
      "memory usage: 2.9 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_df.info()\n",
    "X_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score (Logistic Regression - unscaled): 0.5253083794130158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model\n",
    "model.fit(X_train_df, y_train_df)\n",
    "model.score(X_test_df, y_test_df)\n",
    "\n",
    "print(f'Model Score (Logistic Regression - unscaled): {model.score(X_test_df, y_test_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score (unscaled): 1.0\n",
      "Testing Score (unscaled): 0.6142067205444491\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=100).fit(X_train_df, y_train_df)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Training Score (unscaled): {clf.score(X_train_df, y_train_df)}')\n",
    "print(f'Testing Score (unscaled): {clf.score(X_test_df, y_test_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The training score for Random Forest is perfect. However, the testing score is in the realm\n",
    "#of poor discrimination. I think this coincides with my guess that Random Forest's predictive ability\n",
    "#would be compromised by testing data that goes beyond its parameters. However, even with that\n",
    "#considerable drop in accuracy, it still did better than the Logistic Regression, which performed abysmally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction: I predict that both the Logistic Regression and Random Forest models will fare\n",
    "#better with scaling on training (2019), but will fare worse on testing (2020), because I predict there\n",
    "#will be a lot of outliers in at the end of Q1 in 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train_df)\n",
    "\n",
    "\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train_df)\n",
    "X_test_scaled = X_scaler.transform(X_test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score (Logistic Regression - scaled): 0.7335176520629519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "\n",
    "model_scaled = LogisticRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train_df)\n",
    "\n",
    "model_scaled.score(X_train_scaled, y_train_df)\n",
    "# model_scaled.score(X_test_scaled, y_test_df)\n",
    "\n",
    "print(f'Model Score (Logistic Regression - scaled): {model_scaled.score(X_test_scaled, y_test_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The scaled Logistic Regression model fared much batter than the unscaled and inched into the \n",
    "#realm of acceptible discrimination, which, considering the two models (2019 vs. 2020), is actually pretty good.\n",
    "#In fact, this is the best testing score out of all the scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score (scaled): 0.5\n",
      "Testing Score (scaled): 0.5\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "\n",
    "clf_scaled = RandomForestClassifier(random_state=1, n_estimators=100).fit(X_train_scaled, y_train_df)\n",
    "\n",
    "print(f'Training Score (scaled): {clf.score(X_train_scaled, y_train_df)}')\n",
    "print(f'Testing Score (scaled): {clf.score(X_test_scaled, y_test_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The scaled random forest model gave the worst possible outcome of 0.5, \n",
    "#which is absolutely indicriminate. \n",
    "#Because the training score was just as bad as the testing score, I believe that this result\n",
    "#was due to the scaling and not a much as reflection of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It appears I was wrong, as the Random Forest model would fare worse when scaled, but\n",
    "#my prediction that the Logistic Regression would do better when scaled was correct."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
